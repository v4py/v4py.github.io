{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d63b07d",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b34de5",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Download NLTK resources. Remove code from START_NLTK_TMP to\n",
    "# END_NLTK_TMP to store them in a permanent location instead of a\n",
    "# temporary directory.\n",
    "# --------------------------- START_NLTK_TMP ---------------------------\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "nltk_data = os.path.join(tempfile.gettempdir(), \"v4py\", \"nltk_data\")\n",
    "os.makedirs(nltk_data, exist_ok=True)\n",
    "os.environ[\"NLTK_DATA\"] = nltk_data\n",
    "# ---------------------------- END_NLTK_TMP ----------------------------\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download([\"punkt\", \"stopwords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc524355",
   "metadata": {},
   "source": [
    "```{epigraph}\n",
    "On second thought, let's not go to [Camel](https://en.wikipedia.org/wiki/Perl#Camel)ot. ’Tis a silly place.\n",
    "\n",
    "-- King Arthur, Monty [Python](https://python.org) and the Holy Grail\n",
    "```\n",
    "\n",
    "## Why programming?\n",
    "\n",
    "When I suggest to fellow linguists that they might want to take up\n",
    "programming as a way to supercharge their abilities to confront and\n",
    "extract meaning from language data, I get a variety of responses. Among\n",
    "the negative ones, two tend to dominate: a fear that it might be too\n",
    "late to start anyway, and a dismissive attitude in the vein of \"why\n",
    "should I even care\".\n",
    "\n",
    "Let's examine these concerns in turn. Regarding the first one, it's\n",
    "never too late, trust me. I myself started programming at uni, and not\n",
    "even in my first year. Back then, I thought I was interested in literary\n",
    "studies, and it took me a while to realize that my interests lay\n",
    "elsewhere. Programming is perhaps the easiest skill to acquire from the\n",
    "comfort of your own home, without the need for formal training (though\n",
    "of course interacting with a live teacher can help jumpstart your\n",
    "learning). There's a wealth of resources available via the internet,\n",
    "this book being one example, and all you need to take full advantage of\n",
    "them is a computer and an internet connection.\n",
    "\n",
    "Much like any other learning experience, it's also a [journey that never\n",
    "really ends](https://nedbatchelder.com/blog/202003/how_long_did_it_take_you_to_learn_python.html).\n",
    "There's always room for improvement and for learning more, so you might\n",
    "as well start now and get on with it. For my part, it's been almost ten\n",
    "years since I set out, and while I consider myself a fairly proficient\n",
    "programmer by this point, I learn new stuff all the time. If you're\n",
    "anything like me, that sense of curiosity that got you into linguistics,\n",
    "and perhaps even an academic career, is likely to be rewarded by\n",
    "pursuing programming as well.\n",
    "\n",
    "I would argue that this sense of curiosity is also what should prevent\n",
    "you from having that second kneejerk negative response, \"why should I\n",
    "even care\". For my part, I can tell you that **programming is very\n",
    "likely the most useful skill I acquired since learning to read**. It\n",
    "really expanded the range of what I'm able to achieve not just in\n",
    "linguistics, but in everyday life as well. Our society increasingly\n",
    "relies on software to go about its daily business, and being able to\n",
    "program puts me in much better control of the tools I must willy-nilly\n",
    "use to be a part of it.\n",
    "\n",
    "One concrete example: have you ever had a month to provide feedback on a\n",
    "Microsoft Word document, only to find yourself pulling an all-nighter\n",
    "just before the deadline because there just wasn't time earlier, and\n",
    "feeling ashamed of the trail of 3AM timestamps you're leaving behind?\n",
    "Word offers the nuclear option of removing all metadata in tracked\n",
    "changes and comments across the board, but that includes author names,\n",
    "which is very conspicuous and feels like an even more flagrant admission\n",
    "of guilt, plus if there are multiple authors, you might need to keep\n",
    "them anyway. Luckily, it turns out you can tease the document apart\n",
    "using a [Python script](https://gist.github.com/dlukes/2b5c2a163cd8adba420aaae0c8ea2c00)\n",
    "and selectively target those pesky timestamps associated with your\n",
    "username. (If this doesn't sound familiar at all, then congratulations,\n",
    "you don't have OCD!)\n",
    "\n",
    "But admittedly, these are just words, to see for yourself, you're going\n",
    "to have to get your hands dirty and spend some time learning what\n",
    "programming feels like, and what it empowers you to do, what new,\n",
    "unsuspected perspectives it opens. This book is an attempt to help you\n",
    "get started on that path. And if it doesn't strike a chord with you, it\n",
    "might at least point you to [other related resources](outro), some of\n",
    "which will hopefully be a better fit.\n",
    "\n",
    "If on the other hand, it turns out this book *is* a good fit for you,\n",
    "then great! And if you end up on the fence, then please consider\n",
    "helping us improve it for future readers like you. The source code of\n",
    "this book lives in a [GitHub\n",
    "repository](https://github.com/v4py/v4py.github.io). Please open issues\n",
    "with requests for clarification, tips for improvement, or even just\n",
    "typos!\n",
    "\n",
    "## Target audience\n",
    "\n",
    "This book is intended as an introduction to programming using the\n",
    "[Python](https://python.org) programming language. No previous\n",
    "programming experience is required, though a basic amount of [technical\n",
    "sophistication](https://www.learnenough.com/command-line-tutorial/basics#aside-technical_sophistication)\n",
    "is needed; you will hopefully acquire a lot more by the time you're done\n",
    "reading it.\n",
    "\n",
    "If you've programmed before, but not in Python, or even in Python, but\n",
    "not with a focus on language data, you might still glean useful\n",
    "information from this book, though the pace might feel sluggish at\n",
    "times. And even if you feel at home in both these areas, there might be\n",
    "tricks or gotchas addressed herein that will help you further refine\n",
    "your skills, though of course your mileage may vary.\n",
    "\n",
    "Finally, if you've never programmed, have no background in linguistics\n",
    "and are not particularly computer-literate, reading this book might\n",
    "prove somewhat challenging, though not impossible with the right amount\n",
    "of dedication. If you make it through, or at least part-way, your\n",
    "feedback on how to make the parts you struggled with more accessible\n",
    "would be absolutely invaluable!\n",
    "\n",
    "## Python gives you wings!\n",
    "\n",
    "```{margin}\n",
    "<img alt=\"Python logo\" style=\"width: 100%;\"\n",
    "  src=\"https://www.python.org/static/community_logos/python-logo-generic.svg\">\n",
    "```\n",
    "\n",
    "So what is this [Python](https://python.org/) business all about? I've\n",
    "said before that learning programming was to me the most transformative\n",
    "new skill since learning to read, but it can also prove an uphill\n",
    "struggle. Python is a good entrypoint because it strikes a good balance\n",
    "between simplicity and flexibility, making the learning experience fun\n",
    "and rewarding and just enough challenging. The comic below might poke\n",
    "fun at this claim to get overzealous Python advocates off their soapbox,\n",
    "but by the same token, it shows that Python indeed has this sort of\n",
    "general reputation, otherwise the joke wouldn't work.\n",
    "\n",
    "![Python XKCD](https://imgs.xkcd.com/comics/python.png)\n",
    "\n",
    "Credit: Randall Munroe, XKCD, <https://xkcd.com/353/>\n",
    "\n",
    "Jokes aside though (which is sort of hard to do in a language named\n",
    "after [Monty Python's Flying\n",
    "Circus](https://en.wikipedia.org/wiki/Monty_Python)), the key reason why\n",
    "Python exhibits these desirable properties is that it was designed with\n",
    "teachability to [curious amateurs](https://blog.dropbox.com/topics/work-culture/-the-mind-at-work--guido-van-rossum-on-how-python-makes-thinking)\n",
    "as a primary goal, and it has stayed an important concern during the\n",
    "thirty odd years that Python has evolved and matured since its first\n",
    "public release in 1990. The result is an approachable programming\n",
    "language which emphasizes readable and easily understandable code --\n",
    "properties which are crucial for beginners, but which also appeal to\n",
    "many seasoned programmers. After all, the computer doesn't care, so we\n",
    "might as well make the language as easy as possible for humans to wrap\n",
    "their head around -- is the general idea.\n",
    "\n",
    "```{epigraph}\n",
    "I don't know how well people know ABC's influence on Python. [...] ABC's\n",
    "design had a very clear, sharp focus. ABC was intended to be a\n",
    "programming language that could be taught to intelligent computer users\n",
    "who were not computer programmers or software developers in any sense.\n",
    "\n",
    "-- Guido van Rossum, creator of Python, in [*The Making of Python*](https://www.artima.com/intv/python.html)\n",
    "```\n",
    "\n",
    "Python was also designed as a **general purpose language**, i.e. it is\n",
    "intended to enable its users to build all kinds of programs in a variety\n",
    "of different domains (though as every programming language, it\n",
    "particularly shines in some and is less well-suited for others). A\n",
    "possible disadvantage of this inclusive approach is that it may be a bit\n",
    "harder to find one's way around the ecosystem of tools and libraries for\n",
    "a particular purpose (e.g. statistics or data science), but it pays off\n",
    "in that you're not limited by the one intended use, which is a good\n",
    "thing whenever you embark on a bigger project. And Python encourages you\n",
    "to do that, making it relatively easy to split your code into reusable\n",
    "modules and manage the complexity inherent in that.\n",
    "\n",
    "Contrast this with another high-level programming language that\n",
    "non-programmers often tend to run into -- as a linguist, you might be\n",
    "familiar with [R](https://www.r-project.org/). R is very specifically\n",
    "focused on data analysis, the use case it optimizes for is calling\n",
    "existing statistical functions in an interactive session, and for that,\n",
    "it works admirably well. For anything else though, it can get really\n",
    "ugly. Since \"regular\" users are mostly meant to consume functions rather\n",
    "than write their own, there is a big gap between the elegant way in\n",
    "which these functions are called, and the messy code with which they're\n",
    "implemented. To be clear, I don't mean to say that the code is messy\n",
    "because the people who wrote it are bad programmers; it's messy because\n",
    "R deliberately made some tradeoffs which make it a complicated language\n",
    "to write larger, reusable pieces of code in, while at the same time\n",
    "making these functions somewhat easier to use.\n",
    "\n",
    "As a consequence, with R, beginners tend to run up against a wall when\n",
    "trying to use it for anything that's not easily achieved by an existing\n",
    "library, and though it deserves an honorable mention for having a lot of\n",
    "libraries with useful functionality, some of them very well-designed\n",
    "(I'm looking at you, [`tidyverse`](https://tidyverse.org/)), it's one of\n",
    "the laws of programming that there will always be at least this one\n",
    "thing in your project that there is no existing library for (or maybe\n",
    "there is, but you can't seem to find it). Not to mention that if you\n",
    "ever get interested in other areas of programming, R's laser-sharp focus\n",
    "on data analysis can become a drawback, as it makes R programming skills\n",
    "less transferrable.\n",
    "\n",
    "This is not to say that Python is a panacea to all, or that it doesn't\n",
    "have drawbacks of its own. It definitely does. My point is simply that\n",
    "it has a much more consistent and gradual learning curve, which makes it\n",
    "less likely you'll quit in frustration, and helps you graduate from\n",
    "beginner to intermediate to advanced over time. Perhaps you like R --\n",
    "and that's totally fine -- but you never got over that hump which\n",
    "separates people who use R packages from people who write them. Learning\n",
    "Python might actually be a good way to get there, by improving your\n",
    "general programming skills to a point where you'll feel confident to\n",
    "tackle that uglier side of R.\n",
    "\n",
    "Python's philosophy can be summed up by the guiding principles contained\n",
    "in *The Zen of Python*, which you can print out in a Python session by\n",
    "importing the `this` module. Especially the first four entries are key\n",
    "to the argument that I'm trying to make here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d410d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687bd0c9",
   "metadata": {},
   "source": [
    "## How to use this book\n",
    "\n",
    "This book actually consists of a series of [Jupyter\n",
    "notebooks](https://jupyter.org/), which is a file format, recognizable\n",
    "by its `.ipynb` extension, which intermixes expository prose with\n",
    "programming code. It can be opened using the\n",
    "[JupyterLab](https://jupyterlab.readthedocs.io/) application, which runs\n",
    "in your browser. In the notebooks, code is stored inside code cells\n",
    "which can be modified and run at will, which encourages interactive\n",
    "exploration and makes learning easier. This is what a code cell looks\n",
    "like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d3c70",
   "metadata": {},
   "source": [
    "You can see the code cell's output right below it -- in this case, it's\n",
    "a plain old `2`.\n",
    "\n",
    "If you can, it's a great idea to follow along in JupyterLab, running the\n",
    "code in each chapter of the book yourself and tinkering with it. There\n",
    "are several options for that. The easiest one is to use either the\n",
    "**Binder** or **JupyterHub** buttons under the <i class=\"fas fa-rocket\"></i>\n",
    "icon at the top of the page, which will take care of everything for you\n",
    "and open an interactive version of this text in your browser, without\n",
    "you needing to install anything on your computer.\n",
    "\n",
    "Note that the second button requires that you have an account at\n",
    "<https://jupyter.korpus.cz> (attendees of the V4Py summer school do).\n",
    "The notebook corresponding to the chapter you're reading should\n",
    "automatically open; if it doesn't, try reloading the page, or as a last\n",
    "resort, navigating to the `v4py.github.io` folder and opening the\n",
    "appropriate notebook manually.\n",
    "\n",
    "```{margin}\n",
    "If you do end up installing Python yourself, make sure you install\n",
    "**Python 3**. The previous major version, Python 2, has reached\n",
    "end-of-life at the end of 2019 and is no longer in active development.\n",
    "For a beginning programmer with an interest in linguistics, Python 3 is\n",
    "an improvement in every way, because it is much stricter about how it\n",
    "handles text data, making data corruption or silent processing errors\n",
    "which yield spurious results much less likely.\n",
    "```\n",
    "\n",
    "If you want to install Python on your own computer and run JupyterLab\n",
    "locally, I would suggest using [the Anaconda\n",
    "Distribution](https://www.anaconda.com/distribution/), which installs\n",
    "Python alongside many popular additional packages and libraries for data\n",
    "analysis. In that case, you'll be opening JupyterLab via the [Anaconda\n",
    "Navigator](https://docs.anaconda.com/anaconda/navigator/), and you'll\n",
    "need to [download the notebooks\n",
    "manually](https://github.com/v4py/v4py.github.io/archive/master.zip)\n",
    "(after unzipping, the notebooks are in the `content/` subdirectory). If\n",
    "you don't mind downloading the notebooks individually, you can also use\n",
    "the download button at the top of the page, but that won't get you any\n",
    "of the additional files that some of the notebooks rely on.\n",
    "\n",
    "If you want to learn more about using notebooks, [here's a gallery of\n",
    "interesting notebooks to help you get acquainted with the\n",
    "format](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks),\n",
    "including some introductory tutorials on how to use it right. The\n",
    "JupyterLab notebook user interface is described in more detail in [their\n",
    "docs](https://jupyterlab.readthedocs.io/en/latest/user/notebook.html).\n",
    "Finally, some usage tips which I personally find useful can be found in\n",
    "the [this blog post](https://dlukes.github.io/jupyter-magic.html).\n",
    "\n",
    "## Diving right in: a frequency analysis of this text\n",
    "\n",
    "To get our feet wet, let's do a quick frequency analysis of the text\n",
    "you're currently reading. If you've never programmed before, don't worry\n",
    "if parts (or all) of the code below seems a little mysterious!  We'll\n",
    "cover all of that in much more detail in the following chapters.\n",
    "However, before we dive into the particulars, I think it's a good idea\n",
    "to get acquainted with what actual useful Python code looks like, so\n",
    "that we have a general picture of where we're headed. Without a global\n",
    "perspective and a clear goal in our heads, it's easy to get discouraged\n",
    "by the many seemingly unconnected details that await us along the way.\n",
    "\n",
    "So take a while to look at each code chunk below, try and figure out\n",
    "what its purpose might be and how it achieves it, try and discover\n",
    "repeating patterns in Python's syntax and their meaning. Read the\n",
    "commentary and let the programming vocabulary soak into your brain. It's\n",
    "alright to be confused, it's OK not to understand precisely what each\n",
    "and every word means. The goal at this point is to get familiar with how\n",
    "Python code looks and how the terminology sounds, even if you don't\n",
    "fully understand what's happening yet.\n",
    "\n",
    "```{margin}\n",
    "**HTML** is the [Hypertext Markup\n",
    "Language](https://en.wikipedia.org/wiki/HTML) and it's what web pages\n",
    "are built from, specifically their structure. Layout is mostly done\n",
    "using [CSS](https://en.wikipedia.org/wiki/Cascading_Style_Sheets) and\n",
    "interactive features with\n",
    "[JavaScript](https://en.wikipedia.org/wiki/JavaScript).\n",
    "```\n",
    "\n",
    "We start by **importing** `HTMLSession` from the\n",
    "[`requests_html`](http://html.python-requests.org) **library**, which\n",
    "contains functionality related to fetching HTML pages from the web.  We\n",
    "create a fresh `HTMLSession` **object** and store it in the `session`\n",
    "**variable**. Think of it as a simple web browser inside Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9d35b",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "**HTTP** stands for [Hypertext Transfer\n",
    "Protocol](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol).\n",
    "It's the main protocol used for sending around data on the web.\n",
    "```\n",
    "\n",
    "We can fetch the page you're currently reading by calling the `get()`\n",
    "**method** of the `session` object and passing it the link to this\n",
    "website as an **argument**. We get back an HTTP response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b392178",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://v4py.github.io/intro.html\"\n",
    "response = session.get(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388ee11c",
   "metadata": {},
   "source": [
    "Inspecting the `response` variable, we see `<Response [200]>`. `200` is\n",
    "the [HTTP status\n",
    "code](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status) which\n",
    "indicates that all went well with our request and we received a\n",
    "sucessful response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7fc441",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd85f1",
   "metadata": {},
   "source": [
    "If we don't know or remember which HTTP status code is which, we can\n",
    "check that everything is fine by inspecting the `.ok` **attribute** on\n",
    "the `response` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9010eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f0303",
   "metadata": {},
   "source": [
    "The contents of the web page are stored in the `.html` attribute of the\n",
    "`response` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ef093",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535913cf",
   "metadata": {},
   "source": [
    "That attribute is itself an object with attributes and methods of its\n",
    "own, which allow us to inspect it and manipulate it. For instance, it\n",
    "has in turn its own `.html` attribute, which contains the raw HTML code\n",
    "underlying the web page you're reading, stored as a **string** of\n",
    "**characters**. We can take a look at a **slice** of the first 50\n",
    "characters of the string using the `[:50]` syntax, just to make sure we\n",
    "downloaded the right document. If you're running this notebook inside\n",
    "JupyterLab, you can delete the square brackets and inspect the full\n",
    "HTML; I've not done that here to save some space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06116d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.html.html[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811519a",
   "metadata": {},
   "source": [
    "Uh-oh, I don't remember reading anything about any doctypes at the\n",
    "beginning of this text. What's this all about? Well this is all part of\n",
    "the HTML language, which tells your browser how to display this web\n",
    "page. Trouble is, from our point of view as linguists, this is just junk\n",
    "that we need to get rid of. One thing we could try is the `.text`\n",
    "attribute, which extracts only the text parts of a web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9eba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 50 characters\n",
    "response.html.text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d543dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last 50 characters\n",
    "response.html.text[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2af88",
   "metadata": {},
   "source": [
    "That looks somewhat better, but there's clearly still some \"junk\" left.\n",
    "Turns out that the \"text\" content of an HTML page includes not only all\n",
    "the stuff that's visible on the page (navigation elements, button\n",
    "labels, and other things we probably want to exclude from our analysis),\n",
    "but also invisible things like JavaScript programs which add\n",
    "interactivity to the page (surrounded by `<script/>` tags) or CSS styles\n",
    "which define the layout and other aesthetic aspects of the page\n",
    "(surrounded by `<style/>` tags).\n",
    "\n",
    "Ideally, we'd like to get rid of all of this. How to achieve that? We\n",
    "first need to figure out which parts of the HTML enclose the content\n",
    "we're interested in. For that, we'll use our browser's inspector tools.\n",
    "If you right click anywhere on this page, you should get a menu where\n",
    "one of the items says something like *Inspect* or *Inspect Element*.\n",
    "Click on that and a pane will open beside the page which lets you peek\n",
    "under the hood of this page. If you right click on this paragraph\n",
    "specifically and select *Inspect Element*, the inspector will focus on\n",
    "where in the HTML hierarchy this particular paragraph is placed.\n",
    "\n",
    "![Firefox inspector screenshot](images/intro/inspector.png)\n",
    "\n",
    "We can see that this paragraph is contained with a `<div/>` HTML element\n",
    "which has a class of `rendered_html`, among others. This sounds like a\n",
    "property which could be true of all the interesting content on this page\n",
    "-- after all, we know it was *rendered* from a Jupyter notebook to HTML\n",
    "-- so let's go on a limb here and retrieve all of those `divs` using the\n",
    "`.find()` method. This method uses [CSS\n",
    "selectors](https://www.w3schools.com/cssref/css_selectors.asp) to slice\n",
    "and dice the page; all we need to know right now is that the syntax to\n",
    "find all HTML elements of a certain class is to prefix the class name\n",
    "with a period, so `.rendered_html` in our case. We get back a **list**\n",
    "of `divs`; the `clean=True` **keyword argument** makes sure that we\n",
    "throw away those pesky invisible `<script/>` and `<style/>` tags, if\n",
    "any. Again, I'm showing just a slice of the list to save space -- the\n",
    "first 5 divs using the `[:5]` syntax -- but you can delete those square\n",
    "brackets and re-evaluate the cell to see the full list should you wish\n",
    "so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf421f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs = response.html.find(\".rendered_html\", clean=True)\n",
    "divs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ec0ce",
   "metadata": {},
   "source": [
    "<!-- TODO: explain escape sequence or later? -->\n",
    "\n",
    "Each of these `divs` has a `.text` attribute, which hopefully contains\n",
    "reasonable text and not some junk. We'd like to lump it all together\n",
    "into one long string before moving on to further processing, because we\n",
    "don't really care which part of the text was in which `div`, we just\n",
    "want to have it all in one place to make things easy. So we can join all\n",
    "of those `.text` attributes into one string by splicing a **newline**\n",
    "character, written using the **escape sequence** `\"\\n\"`, in between\n",
    "every two pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\\n\".join(div.text for div in divs)\n",
    "string[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ac79e",
   "metadata": {},
   "source": [
    "<!-- TODO: explain function vs. method or later? -->\n",
    "\n",
    "This is starting to look good! We've possibly thrown out some stuff that\n",
    "could have been included, like the chapter title, but it's definitely\n",
    "much better than accidentally including all that JavaScript junk in our\n",
    "analysis. Just to see how much stuff we've gotten rid of, we can compare\n",
    "the number of characters using the `len()` **function**.\n",
    "\n",
    "<!-- TODO: add something like \"we've cut it roughly in half!\" based on how -->\n",
    "<!-- much it turns out to be in the end -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.html.full_text), len(response.html.text), len(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4bda1e",
   "metadata": {},
   "source": [
    "Now in order to do a frequency analysis, we need to split that text into\n",
    "words or **tokens**, which is a technical term used when we want to\n",
    "avoid the kind of philosophical hairsplitting that linguists sometimes\n",
    "engage in with respect to what is or is not a word. Referring to words\n",
    "as 'tokens' is basically a way of saying, \"I don't want to pick a fight\n",
    "about the precise meaning of 'word' right now, I made a pragmatic\n",
    "decision to split the text into pieces which broadly make sense, but of\n",
    "course reasonable people might disagree on the details.\" It also allows\n",
    "us to be precise that we are referring to specific *instances* of words.\n",
    "The word 'word' is ambiguous, a sentence like \"I know I screwed up.\" can\n",
    "be described as containing either 5 (total running) words or 4\n",
    "(different) words. If we want to avoid confusion, we can say instead\n",
    "that it consists of **5 tokens** and **4 types**.\n",
    "\n",
    "Word-splitting or **tokenization** is a trickier problem than it might\n",
    "seem at first glance, because punctuation keeps getting in the way. So\n",
    "let's not do it manually ourselves, let's use instead the\n",
    "`word_tokenize()` function in the [`nltk`](http://www.nltk.org/)\n",
    "library, which hopefully covers some of the edge cases we wouldn't think\n",
    "of right off the bat if we were to implement it ourselves off the top of\n",
    "our head. This function **returns** a list of strings, and again we can\n",
    "do a sanity check by inspecting a slice of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ca88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tokenized = nltk.word_tokenize(string.lower())\n",
    "tokenized[100:115]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e687d6d0",
   "metadata": {},
   "source": [
    "Looks fine. Notice that before tokenizing the string, we converted in to\n",
    "**lowercase** using the `.lower()` **method**. This is because in our\n",
    "frequency analysis, we probably don't want to make a distinction between\n",
    "e.g. `token` and `Token`. They refer to the same thing, so they should\n",
    "be counted together, but the computer doesn't know that, as far as it's\n",
    "concerned, `token` is as different from `Token` as it is from\n",
    "`grapefruit`, so it's our job to make them exactly the same by\n",
    "lowercasing everything beforehand. We can measure the length of the list\n",
    "and thus get the number of tokens using the `len()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df528bff",
   "metadata": {},
   "source": [
    "That's quite a lot, thanks for reading so far!\n",
    "\n",
    "But hang on, that count is likely to be somewhat inflated. First of all,\n",
    "a lot of the tokens in the `tokenized` list are junk, at least\n",
    "linguistically speaking, they are special characters related to the\n",
    "notebook format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55670f",
   "metadata": {},
   "source": [
    "Second of all, it doesn't take a linguist to realize that the most\n",
    "common words in an English text will be words like `a` or `the`. We\n",
    "probably don't want to include those in our frequency analysis, since\n",
    "they're not very interesting, they don't tell us a lot. Luckily, `nltk`\n",
    "has a list of these uninteresting **stopwords** for English which we can\n",
    "load and store in a **set**, so that we can quickly check if a given\n",
    "token is a stopword or not. The stopwords are stored in their lowercase\n",
    "form, so it comes in handy that we already lowercased our input string\n",
    "prior to tokenizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbefc85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_list = stopwords.words(\"english\")\n",
    "stop_set = set(stop_list)\n",
    "stop_list[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f994c2e",
   "metadata": {},
   "source": [
    "We can now get rid of any unwanted tokens. The following code snippet is\n",
    "a bit more complicated than the previous ones, it involves some\n",
    "non-linear **control flow**, which is a fancy way of saying the code\n",
    "doesn't just linearly execute from top to bottom, but it can run around\n",
    "in circles for a while (the **for** statement) or potentially skip some\n",
    "parts depending on whether a condition **evaluates** to true or false\n",
    "(the **if** statement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c930e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new empty\n",
    "cleaned = []\n",
    "# iterate over all the tokens in the tokenized list\n",
    "for token in tokenized:\n",
    "    # check if current token is \"interesting\"\n",
    "    if token.isalpha() and token not in stop_set:\n",
    "        # if so, append it to the cleaned list\n",
    "        cleaned.append(token)\n",
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ba517",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "‡ At least partially -- if you actually inspect the contents of `cleaned`,\n",
    "you'll see that it still contains many tokens, like `cells` or\n",
    "`metadata`, which look like regular words, but they don't occur in this\n",
    "text, they're part of the notebook format structure.\n",
    "```\n",
    "\n",
    "`cleaned` is a lot shorter than `tokenized`, so it looks like it\n",
    "worked!‡ Note how Python uses **indentation** to encode the hierarchy\n",
    "of **statements** in the code: everything which is indented under the\n",
    "**for-loop header** on the second line is part of the **for-loop body**\n",
    "and gets executed for each token in the tokenized list. Similarly,\n",
    "everything indented under the **if header** only gets executed if the\n",
    "conditional **expression** is satisfied. By dedenting, we escape the\n",
    "tyranny of those fors and ifs, so that the last line gets executed only\n",
    "once, after the for-loop has completed.\n",
    "\n",
    "Notice also that with suitably chosen variable names, Python code can\n",
    "read almost like English. Readability is one of Python's main strengths,\n",
    "though it can sometimes be a pitfall for beginners -- when they're not\n",
    "sure how to do something in Python, they try to write it in an\n",
    "English-like way and hope for the best, but this approach can yield\n",
    "valid Python code which however does something different than the plain\n",
    "English interpretation would suggest.\n",
    "\n",
    "We are now finally in a position to create a **frequency distribution**,\n",
    "using the `nltk.FreqDist` **class**. It's easy, we just pass it our list\n",
    "of clean tokens.\n",
    "\n",
    "```{margin}\n",
    "Each object in Python has a **type**. Some of those are built-in, like\n",
    "strings, lists or sets. But users can also define new types of their\n",
    "own; those are called **classes**. `nltk.FreqDist` is one of those\n",
    "user-defined types.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(cleaned)\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f5707",
   "metadata": {},
   "source": [
    "We can access individual **values** inside the frequency distribution by\n",
    "requesting them using the corresponding **key**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist[\"python\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ee04c7",
   "metadata": {},
   "source": [
    "We can also list the top $n$ items using the `.most_common()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb30c30",
   "metadata": {},
   "source": [
    "Based on the most frequent lexical items, it looks like this is a text\n",
    "about Python programming and language data! That checks out.\n",
    "\n",
    "Finally, we can visualize this result using a wordcloud, to get a quick\n",
    "and intuitive overview of these important words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpy.vis import wordcloud\n",
    "\n",
    "wordcloud(freq_dist, size=(800, 400), rounded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b074b2e",
   "metadata": {},
   "source": [
    "Whew! That was actually a lot of work. Now that we've figured out how to\n",
    "do this, we could package all of these steps into a reusable recipe, so\n",
    "that we don't have to re-cobble all of this together if we want to run a\n",
    "same analysis on a different chapter. We can do so by writing a\n",
    "function. Again, as with for-loops and if statements, everything that's\n",
    "indented under the function header starting with `def` is part of the\n",
    "function body, and will be run step by step each time the function is\n",
    "**called**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bec65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapter_wordcloud(link, size=(800, 400), rounded=True):\n",
    "    session = HTMLSession()\n",
    "    response = session.get(link)\n",
    "    divs = response.html.find(\".rendered_html\", clean=True)\n",
    "    string = \"\\n\".join(div.text for div in divs)\n",
    "    tokenized = nltk.word_tokenize(string.lower())\n",
    "    stop_set = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    cleaned = []\n",
    "    for token in tokenized:\n",
    "        if token.isalpha() and token not in stop_set:\n",
    "            cleaned.append(token)\n",
    "    # if we want just the wordcloud, we can also directly create it from\n",
    "    # a list of tokens, without making an intermediate nltk.FreqDist\n",
    "    return wordcloud(cleaned, size=size, rounded=rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704d6a1",
   "metadata": {},
   "source": [
    "The `return` keyword specifies what the result is that the function\n",
    "spits out at the other end. Once the function reaches a return\n",
    "statement, it stops execution and gives the result back to whoever\n",
    "called the function.\n",
    "\n",
    "We can now easily create a wordcloud based on the final chapter of this\n",
    "book, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2033495",
   "metadata": {
    "tags": [
     "full-width"
    ]
   },
   "outputs": [],
   "source": [
    "chapter_wordcloud(\"https://v4py.github.io/outro.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f2107",
   "metadata": {},
   "source": [
    "Indeed, we can use this function on any chapter in any online book\n",
    "created (much like the present book) with the [jupyter-book]() package,\n",
    "because they all use the same HTML structure. For instance, here's a\n",
    "wordcloud of the chapter on [*Regular\n",
    "Expressions*](https://www.textbook.ds100.org/ch/08/text_regex.html) from\n",
    "the book [*Principles and Techniques of Data\n",
    "Science*](https://www.textbook.ds100.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f6e53",
   "metadata": {
    "tags": [
     "full-width"
    ]
   },
   "outputs": [],
   "source": [
    "chapter_wordcloud(\"https://www.textbook.ds100.org/ch/08/text_regex.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8161b",
   "metadata": {},
   "source": [
    "This is the real power of programming: once you've figured out and\n",
    "tweaked a processing and analysis recipe, you can apply it to similar\n",
    "data with lightning speed and each time consistently in exactly the same\n",
    "way.\n",
    "\n",
    "To wrap up, let me reiterate that I realize this is a lot to take in if\n",
    "this is your first time seeing Python code, and even more so if this is\n",
    "your first time seeing any programming language code whatsoever. Again,\n",
    "it's totally fine if you don't understand all the details at this point.\n",
    "I encourage you to revisit this extended worked example once you're done\n",
    "reading the book, as a way to reflect on what you've learned and bring\n",
    "it all together.\n",
    "\n",
    "<!-- TODO: remove or develop -->\n",
    "\n",
    "<!-- # NLTK Book -->\n",
    "\n",
    "<!-- A great, longer free resource. <http://www.nltk.org/book/> -->\n",
    "\n",
    "<!-- ![NLTK Book](./nltk_book.jpg) -->\n",
    "\n",
    "<!-- Credit: ??? -->\n",
    "\n",
    "<!-- # The NLP pipeline -->\n",
    "\n",
    "<!-- NOTE: maybe leave this out? Not strictly necessary, this is probably -->\n",
    "<!-- better to discuss in class, plus I shouldn't rely too much on NLTK Book -->\n",
    "<!-- materials for licensing reasons. -->\n",
    "\n",
    "<!-- ![NLP](./dialogue.png) -->\n",
    "\n",
    "<!-- Credit: ??? -->\n",
    "\n",
    "<!-- # Overview -->\n",
    "\n",
    "<!-- - Python basics (functions, control flow, collections) -->\n",
    "<!-- - The NLTK [package](http://www.nltk.org/) & -->\n",
    "<!--   [book](http://www.nltk.org/book) as a good starting point for people -->\n",
    "<!--   interested in language data -->\n",
    "<!-- - [How text is represented inside -->\n",
    "<!--   computers](https://dlukes.github.io/unicode.html) -->\n",
    "<!-- - Regular expressions in Python -->\n",
    "<!-- - Accessing web services (\"REST APIs\") from Python & Automatic -->\n",
    "<!--   annotation of language data (tagging, parsing) - both courtesy of -->\n",
    "<!--   [Rudolf Rosa](https://ufal.mff.cuni.cz/rudolf-rosa) -->\n",
    "<!-- - Getting data into Python (raw text & tabular data) -->\n",
    "<!-- - Some visualizations (dispersion plots, wordclouds) -->\n",
    "<!-- - Case studies: collocation strength, keyword analysis -->\n",
    "\n",
    "<!-- vim: set spell spelllang=en: -->"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   13,
   17,
   35,
   235,
   237,
   251,
   253,
   341,
   345,
   357,
   360,
   368,
   370,
   376,
   378,
   383,
   385,
   397,
   399,
   408,
   413,
   416,
   456,
   459,
   472,
   475,
   488,
   490,
   515,
   520,
   532,
   534,
   543,
   545,
   557,
   563,
   573,
   583,
   621,
   624,
   629,
   631,
   635,
   637,
   645,
   649,
   660,
   675,
   685,
   689,
   699,
   703
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}