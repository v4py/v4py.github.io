<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Introduction</title>
  <meta name="description" content="# Introduction```python tags=["remove_cell"]# Download NLTK resources. Remove code from START_NLTK_TMP to# END_NLTK_TMP to store them in a permanent location...">

  <link rel="canonical" href="https://v4py.github.io//src/intro.html">
  <link rel="alternate" type="application/rss+xml" title="An Introduction to Python for Linguists" href="https://v4py.github.io//feed.xml">

  <meta property="og:url"         content="https://v4py.github.io//src/intro.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Introduction" />
<meta property="og:description" content="# Introduction```python tags=["remove_cell"]# Download NLTK resources. Remove code from START_NLTK_TMP to# END_NLTK_TMP to store them in a permanent location..." />
<meta property="og:image"       content="https://v4py.github.io/images/v4py_logo_wide.svg" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "https://v4py.github.io//src/intro.html",
  "headline": "Introduction",
  "datePublished": "2020-03-31T17:44:37+02:00",
  "dateModified": "2020-03-31T17:44:37+02:00",
  "description": "# Introduction```python tags=["remove_cell"]# Download NLTK resources. Remove code from START_NLTK_TMP to# END_NLTK_TMP to store them in a permanent location...",
  "author": {
    "@type": "Person",
    "name": "David Lukeš, Rudolf Rosa"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://v4py.github.io/",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://v4py.github.io/",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/assets/css/styles.css">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/images/v4py_logo.svg">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    },
    
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>


  <!-- DOM updating function -->
  <script src="/assets/js/page/dom-update.js"></script>

  <!-- Selectors for elements on the page -->
  <script src="/assets/js/page/documentSelectors.js"></script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script src="/assets/js/page/anchors.js" async></script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->



  <!-- Load the auto-generating TOC (non-async otherwise the TOC won't load w/ turbolinks) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.8.1/tocbot.min.js" async></script>
  <script src="/assets/js/page/tocbot.js"></script>

  <!-- Google analytics -->
  


  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  
<script>
/**
  * To auto-embed hub URLs in interact links if given in a RESTful fashion
 */

function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}
    
function dict2param(dict) {
    params = Object.keys(dict).map(function(k) {
        return encodeURIComponent(k) + '=' + encodeURIComponent(dict[k])
    });
    return params.join('&')
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return dict2param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = document.querySelectorAll("a").forEach(function(link) {
    var href = link.href;
    // If the link is an internal link...
    if (href.search("https://v4py.github.io") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['jupyterhub'] = hub;
      } else {
        // Create the REST params
        params = {'jupyterhub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + dict2param(params);
      link.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}


// Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    jupyterHubUrl = rest['jupyterhub'];
    var hubType = null;
    var hubUrl = null;
    if (jupyterHubUrl !== undefined) {
      hubType = 'jupyterhub';
      hubUrl = jupyterHubUrl;
    }

    if (hubType !== null) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);

      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      var interactButtons = document.querySelectorAll("button.interact-button")
      var lastButton = interactButtons[interactButtons.length-1];
      var link = lastButton.parentElement;

      // If we've already run this, skip the link updating
      if (link.nextElementSibling !== null) {
        return;
      }

      // Update the link and add context div
      var href = link.getAttribute('href');
      if (lastButton.id === 'interact-button-binder') {
        // If binder links exist, we need to re-work them for jupyterhub
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // If localhost, assume we're working from a local Jupyter server and remove `/hub`
          first = [hubUrl, 'git-sync'].join('/')
        } else {
          first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
        }
        href = first + '?' + binder2Jupyterhub(href);
      } else {
        // If interact button isn't binderhub, assume it's jupyterhub
        // If JupyterHub links, we only need to replace the hub url
        href = href.replace("https://jupyter.korpus.cz", hubUrl);
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // Assume we're working from a local Jupyter server and remove `/hub`
          href = href.replace("/hub/user-redirect", "");
        }
      }
      link.setAttribute('href', decodeURIComponent(href));

      // Add text after interact link saying where we're launching
      hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
      link.insertAdjacentHTML('afterend', '<div class="interact-context">on ' + hubUrlNoHttp + '</div>');

      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

runWhenDOMLoaded(updateInteractLink)
document.addEventListener('turbolinks:load', updateInteractLink)
</script>


  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script src="/assets/js/page/copy-button.js" async></script>

  <!-- Hide cell code -->
  <script src="/assets/js/page/hide-cell.js" async></script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/assets/css/styles.css",
        style: "#textbook_content {padding-top: 40px};",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList,
        documentTitle: "An Introduction to Python for Linguists"
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- Include the ThebeLab config so it gets reloaded on each page -->
    <script type="text/x-thebe-config">{
    requestKernel: true,
    binderOptions: {
    repo: "v4py/v4py.github.io",
    ref: "master",
    },
    codeMirrorConfig: {
    theme: "abcdef",
    mode: "python"
    },
    kernelOptions: {
    kernelName: "python3",
    path: ""
    }
}
</script>

    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://v4py.github.io"><img src="/images/v4py_logo_wide.svg" class="textbook_logo" id="sidebar-logo" alt="textbook logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">An Introduction to Python for Linguists</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="https://dlukes.github.io/">
        <a class="c-sidebar__entry"
          href="https://dlukes.github.io/"
        >
          
          David Lukeš
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="https://ufal.mff.cuni.cz/rudolf-rosa">
        <a class="c-sidebar__entry"
          href="https://ufal.mff.cuni.cz/rudolf-rosa"
        >
          
          Rudolf Rosa
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li><h2 class="c-sidebar__title">Table of contents</li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/intro">
        <a class="c-sidebar__entry"
          href="/intro.html"
        >
          
            1.
          
          Introduction
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/basics">
        <a class="c-sidebar__entry"
          href="/basics.html"
        >
          
            2.
          
          A tour of Python and NLTK
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/unicode">
        <a class="c-sidebar__entry"
          href="/unicode.html"
        >
          
            3.
          
          Text inside the computer
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/data">
        <a class="c-sidebar__entry"
          href="/data.html"
        >
          
            4.
          
          Getting your data into Python
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/rest">
        <a class="c-sidebar__entry"
          href="/rest.html"
        >
          
            5.
          
          Working with online resources
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/regex">
        <a class="c-sidebar__entry"
          href="/regex.html"
        >
          
            6.
          
          Regular expressions
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/outro">
        <a class="c-sidebar__entry"
          href="/outro.html"
        >
          
            7.
          
          Parting words
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li><h2 class="c-sidebar__title">Links</li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="https://ufal.mff.cuni.cz/">
        <a class="c-sidebar__entry"
          href="https://ufal.mff.cuni.cz/"
        >
          
          ÚFAL MFF UK
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="https://korpus.cz/">
        <a class="c-sidebar__entry"
          href="https://korpus.cz/"
        >
          
          Czech National Corpus
        </a>
      </li>

      
      

      

      
      

      

      
    
  </ul>
  <p class="sidebar_footer">Sponsored by <a href="https://www.visegradfund.org/">Visegrad Fund</a> grant nr. 21820079 "Training Digital Scholars: Knowledge Exchange between V4 and Austria". Available under the terms of the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> license.</p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button
      id="js-sidebar-toggle"
      class="hamburger hamburger--arrowalt is-active"
    >
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><img src="/assets/images/download-solid.svg" alt="Download" /></button>
    <div class="download-buttons">
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">.pdf</button></a>
    </div>
</div>


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title"><img src="/assets/images/list-solid.svg" alt="Search" />   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/search.html" class="topbar-right-button" id="search-button">
    <img src="/assets/images/search-solid.svg" alt="Search" />
  </a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
              <h1 id="introduction">Introduction</h1>

<p>```python tags=[“remove_cell”]</p>
<h1 id="download-nltk-resources-remove-code-from-start_nltk_tmp-to">Download NLTK resources. Remove code from START_NLTK_TMP to</h1>
<h1 id="end_nltk_tmp-to-store-them-in-a-permanent-location-instead-of-a">END_NLTK_TMP to store them in a permanent location instead of a</h1>
<h1 id="temporary-directory">temporary directory.</h1>
<h1 id="-start_nltk_tmp-">————————— START_NLTK_TMP —————————</h1>
<p>import os
import tempfile</p>

<p>nltk_data = os.path.join(tempfile.gettempdir(), “v4py”, “nltk_data”)
os.makedirs(nltk_data, exist_ok=True)
os.environ[“NLTK_DATA”] = nltk_data</p>
<h1 id="--end_nltk_tmp--">—————————- END_NLTK_TMP —————————-</h1>

<p>import nltk</p>

<p>nltk.download([“punkt”, “stopwords”])</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;!-- #md tags=["popout"] --&gt;

**Acknowledgments:** The authors are grateful to [Visegrad
Fund](https://www.visegradfund.org/) grant nr. 21820079 "Training
Digital Scholars: Knowledge Exchange between V4 and Austria" for kindly
sponsoring this project.

&lt;!-- #endmd --&gt;

&lt;!-- #md tags=["epigraph"] --&gt;

&gt; On second thought, let's not go to Camelot. 'Tis a silly place.
&gt;
&gt; -- King Arthur, Monty [Python](https://python.org) and the Holy Grail

&lt;!-- #endmd --&gt;

# Why programming?

When I suggest to fellow linguists that they might want to take up
programming as a way to supercharge their abilities to confront and
extract meaning from language data, I get a variety of responses. Among
the negative ones, two tend to dominate: a fear that it might be too
late to start anyway, and a dismissive attitude in the vein of "why
should I even care".

Let's examine these concerns in turn. Regarding the first one, it's
never too late, trust me. I myself started programming at uni, and not
even in my first year. Back then, I thought I was interested in literary
studies, and it took me a while to realize that my interests lay
elsewhere. Programming is perhaps the easiest skill to acquire from the
comfort of your own home, without the need for formal training (though
of course interacting with a live teacher can help jumpstart your
learning). There's a wealth of resources available via the internet,
this book being one example, and all you need to take full advantage of
them is a computer and an internet connection.

Much like any other learning experience, it's also a journey that never
really ends. There's always room for improvement and for learning more,
so you might as well start now and get on with it. For my part, it's
been almost ten years since I set out, and while I consider myself a
fairly proficient programmer by this point, I learn new stuff all the
time. If you're anything like me, that sense of curiosity that got you
into linguistics, and perhaps even an academic career, is likely to be
rewarded by pursuing programming as well.

I would argue that this sense of curiosity is also what should prevent
you from having that second kneejerk negative response, "why should I
even care". For my part, I can tell you that **programming is very
likely the most useful skill I acquired since learning to read**. It
really expanded the range of what I'm able to achieve not just in
linguistics, but in everyday life as well. Our society increasingly
relies on software to go about its daily business, and being able to
program puts me in much better control of the tools I must willy-nilly
use to be a part of it.

One concrete example: have you ever had a month to provide feedback on a
Microsoft Word document, only to find yourself pulling an all-nighter
just before the deadline because there just wasn't time earlier, and
feeling ashamed of the trail of 3AM timestamps you're leaving behind?
Word offers the nuclear option of removing all metadata in tracked
changes and comments across the board, but that includes author names,
which is very conspicuous and feels like an even more flagrant admission
of guilt, plus if there are multiple authors, you might need to keep
them anyway. Luckily, it turns out you can tease the document apart
using a [Python
script](https://gist.github.com/dlukes/2b5c2a163cd8adba420aaae0c8ea2c00)
and selectively target those pesky timestamps associated with your
username. (If this doesn't sound familiar at all, then congratulations,
you don't have OCD!)

But admittedly, these are just words, to see for yourself, you're going
to have to get your hands dirty and spend some time learning what
programming feels like, and what it empowers you to do, what new,
unsuspected perspectives it opens. This book is an attempt to help you
get started on that path. And if it doesn't strike a chord with you, it
might at least point you to [other related resources](outro), some of
which will hopefully be a better fit.

If on the other hand, it turns out this book *is* a good fit for you,
then great! And if you end up on the fence, then please consider
helping us improve it for future readers like you. The source code of
this book lives in a [GitHub
repository](https://github.com/v4py/v4py.github.io). Please open issues
with requests for clarification, tips for improvement, or even just
typos!

# Target audience

This book is intended as an introduction to programming using the
[Python](https://python.org) programming language. No previous
programming experience is required, though a basic amount of [technical
sophistication](https://www.learnenough.com/command-line-tutorial/basics#aside-technical_sophistication)
is needed; you will hopefully acquire a lot more by the time you're done
reading it.

If you've programmed before, but not in Python, or even in Python, but
not with a focus on language data, you might still glean useful
information from this book, though the pace might feel sluggish at
times. And even if you feel at home in both these areas, there might be
tricks or gotchas addressed herein that will help you further refine
your skills, though of course your mileage may vary.

Finally, if you've never programmed, have no background in linguistics
and are not particularly computer-literate, reading this book might
prove somewhat challenging, though not impossible with the right amount
of dedication. If you make it through, or at least part-way, your
feedback on how to make the parts you struggled with more accessible
would be absolutely invaluable!

# Python gives you wings!

&lt;!-- #md tags=["popout"] --&gt;
&lt;img alt="Python logo" style="width: 100%;"
  src="https://www.python.org/static/community_logos/python-logo-generic.svg"&gt;
&lt;!-- #endmd --&gt;

So what is this [Python](https://python.org/) business all about? I've
said before that learning programming was to me the most transformative
new skill since learning to read, but it can also prove an uphill
struggle. Python is a good entrypoint because it strikes a good balance
between simplicity and flexibility, making the learning experience fun
and rewarding and just enough challenging. The comic below might poke
fun at this claim to get overzealous Python advocates off their soapbox,
but by the same token, it shows that Python indeed has this sort of
general reputation, otherwise the joke wouldn't work.

![Python XKCD](https://imgs.xkcd.com/comics/python.png)

Credit: Randall Munroe, XKCD, &lt;https://xkcd.com/353/&gt;

Jokes aside though (which is sort of hard to do in a language named
after [Monty Python's Flying
Circus](https://en.wikipedia.org/wiki/Monty_Python)), the key reason why
Python exhibits these desirable properties is that it was designed with
teachability to [curious
amateurs](https://blog.dropbox.com/topics/work-culture/-the-mind-at-work--guido-van-rossum-on-how-python-makes-thinking)
as a primary goal, and it has stayed an important concern during the
thirty odd years that Python has evolved and matured since its first
public release in 1990. The result is an approachable programming
language which emphasizes readable and easily understandable code --
properties which are crucial for beginners, but which also appeal to
many seasoned programmers. After all, the computer doesn't care, so we
might as well make the language as easy as possible for humans to wrap
their head around -- is the general idea.

&gt; I don't know how well people know ABC's influence on Python. [...]
&gt; ABC's design had a very clear, sharp focus. ABC was intended to be a
&gt; programming language that could be taught to intelligent computer
&gt; users who were not computer programmers or software developers in any
&gt; sense.
&gt;
&gt; -- Guido van Rossum, creator of Python, in [*The Making of
&gt; Python*](https://www.artima.com/intv/python.html)

Python was also designed as a **general purpose language**, i.e. it is
intended to enable its users to build all kinds of programs in a variety
of different domains (though as every programming language, it
particularly shines in some and is less well-suited for others). A
possible disadvantage of this inclusive approach is that it may be a bit
harder to find one's way around the ecosystem of tools and libraries for
a particular purpose (e.g. statistics or data science), but it pays off
in that you're not limited by the one intended use, which is a good
thing whenever you embark on a bigger project. And Python encourages you
to do that, making it relatively easy to split your code into reusable
modules and manage the complexity inherent in that.

Contrast this with another high-level programming language that
non-programmers often tend to run into -- as a linguist, you might be
familiar with [R](https://www.r-project.org/). R is very specifically
focused on data analysis, the use case it optimizes for is calling
existing statistical functions in an interactive session, and for that,
it works admirably well. For anything else though, it can get really
ugly. Since "regular" users are mostly meant to consume functions rather
than write their own, there is a big gap between the elegant way in
which these functions are called, and the messy code with which they're
implemented. To be clear, I don't mean to say that the code is messy
because the people who wrote it are bad programmers; it's messy because
R deliberately made some tradeoffs which make it a complicated language
to write larger, reusable pieces of code in, while at the same time
making these functions somewhat easier to use.

As a consequence, with R, beginners tend to run up against a wall when
trying to use it for anything that's not easily achieved by an existing
library, and though it deserves an honorable mention for having a lot of
libraries with useful functionality, some of them very well-designed
(I'm looking at you, [`tidyverse`](https://tidyverse.org/)), it's one of
the laws of programming that there will always be at least this one
thing in your project that there is no existing library for (or maybe
there is, but you can't seem to find it). Not to mention that if you
ever get interested in other areas of programming, R's laser-sharp focus
on data analysis can become a drawback, as it makes R programming skills
less transferrable.

This is not to say that Python is a panacea to all, or that it doesn't
have drawbacks of its own. It definitely does. My point is simply that
it has a much more consistent and gradual learning curve, which makes it
less likely you'll quit in frustration, and helps you graduate from
beginner to intermediate to advanced over time. Perhaps you like R --
and that's totally fine -- but you never got over that hump which
separates people who use R packages from people who write them. Learning
Python might actually be a good way to get there, by improving your
general programming skills to a point where you'll feel confident to
tackle that uglier side of R.

Python's philosophy can be summed up by the guiding principles contained
in *The Zen of Python*, which you can print out in a Python session by
importing the `this` module. Especially the first four entries are key
to the argument that I'm trying to make here:

```python
import this
</code></pre></div></div>

<h1 id="how-to-use-this-book">How to use this book</h1>

<p>This book actually consists of a series of <a href="https://jupyter.org/">Jupyter
notebooks</a>, which is a file format, recognizable
by its <code class="language-plaintext highlighter-rouge">.ipynb</code> extension, which intermixes expository prose with
programming code. It can be opened using the
<a href="https://jupyterlab.readthedocs.io/">JupyterLab</a> application, which runs
in your browser. In the notebooks, code is stored inside code cells
which can be modified and run at will, which encourages interactive
exploration and makes learning easier. This is what a code cell looks
like:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div></div>

<p>You can see the code cell’s output right below it – in this case, it’s
a plain old <code class="language-plaintext highlighter-rouge">2</code>.</p>

<p>If you can, it’s a great idea to follow along in JupyterLab, running the
code in each chapter of the book yourself and tinkering with it. There
are several options for that. The easiest one is to use either the <strong>▶
mybinder.org</strong> or <strong>▶ jupyter.korpus.cz</strong> buttons at the top of the
page, which will take care of everything for you and open an interactive
version of this text in your browser, without you needing to install
anything on your computer.</p>

<p>Note that the second button requires that you have an account at
<a href="https://jupyter.korpus.cz">https://jupyter.korpus.cz</a> (attendees of the V4Py summer school do),
and due to some bugs in the software which makes this possible, it
doesn’t work as intended if you’re not already logged in. In that case:</p>

<ol>
  <li>Click on the button once and log into JupyterLab.</li>
  <li>Close the JupyterLab tab.</li>
  <li>Click on the button a second time. JupyterLab should now
automatically open the appropriate notebook.</li>
  <li>If that doesn’t happen, try reloading the page.</li>
</ol>

<!-- #md tags=["popout"] -->

<p>If you do end up installing Python yourself, make sure you install
<strong>Python 3</strong>. The previous major version, Python 2, has reached
end-of-life at the end of 2019 and is no longer in active development.
For a beginning programmer with an interest in linguistics, Python 3 is
an improvement in every way, because it is much stricter about how it
handles text data, making data corruption or silent processing errors
which yield spurious results much less likely.</p>

<!-- #endmd -->

<p>If you want to install Python on your own computer and run JupyterLab
locally, I would suggest using <a href="https://www.anaconda.com/distribution/">the Anaconda
Distribution</a>, which installs
Python alongside many popular additional packages and libraries for data
analysis. In that case, you’ll be opening JupyterLab via the <a href="https://docs.anaconda.com/anaconda/navigator/">Anaconda
Navigator</a>, and you’ll
need to <a href="https://github.com/v4py/v4py.github.io/archive/master.zip">download the notebooks
manually</a>
(after unzipping, the notebooks are in the <code class="language-plaintext highlighter-rouge">content/</code> subdirectory). If
you don’t mind downloading the notebooks individually, you can also use
the download button at the top of the page, but that won’t get you any
of the additional files that some of the notebooks rely on.</p>

<p>If you want to learn more about using notebooks, <a href="https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks">here’s a gallery of
interesting notebooks to help you get acquainted with the
format</a>,
including some introductory tutorials on how to use it right. The
JupyterLab notebook user interface is described in more detail in <a href="https://jupyterlab.readthedocs.io/en/latest/user/notebook.html">their
docs</a>.
Finally, some usage tips which I personally find useful can be found in
the <a href="https://dlukes.github.io/jupyter-magic.html">this blog post</a>.</p>

<h1 id="diving-right-in-a-frequency-analysis-of-this-text">Diving right in: a frequency analysis of this text</h1>

<p>To get our feet wet, let’s do a quick frequency analysis of the text
you’re currently reading. If you’ve never programmed before, don’t worry
if parts (or all) of the code below seems a little mysterious!  We’ll
cover all of that in much more detail in the following chapters.
However, before we dive into the particulars, I think it’s a good idea
to get acquainted with what actual useful Python code looks like, so
that we have a general picture of where we’re headed. Without a global
perspective and a clear goal in our heads, it’s easy to get discouraged
by the many seemingly unconnected details that await us along the way.</p>

<p>So take a while to look at each code chunk below, try and figure out
what its purpose might be and how it achieves it, try and discover
repeating patterns in Python’s syntax and their meaning. Read the
commentary and let the programming vocabulary soak into your brain. It’s
alright to be confused, it’s OK not to understand precisely what each
and every word means. The goal at this point is to get familiar with how
Python code looks and how the terminology sounds, even if you don’t
fully understand what’s happening yet.</p>

<!-- #md tags=["popout"] -->

<p><strong>HTML</strong> is the <a href="https://en.wikipedia.org/wiki/HTML">Hypertext Markup
Language</a> and it’s what web pages
are built from, specifically their structure. Layout is mostly done
using <a href="https://en.wikipedia.org/wiki/Cascading_Style_Sheets">CSS</a> and
interactive features with
<a href="https://en.wikipedia.org/wiki/JavaScript">JavaScript</a>.</p>

<!-- #endmd -->

<p>We start by <strong>importing</strong> <code class="language-plaintext highlighter-rouge">HTMLSession</code> from the
<a href="http://html.python-requests.org"><code class="language-plaintext highlighter-rouge">requests_html</code></a> <strong>library</strong>, which
contains functionality related to fetching HTML pages from the web.  We
create a fresh <code class="language-plaintext highlighter-rouge">HTMLSession</code> <strong>object</strong> and store it in the <code class="language-plaintext highlighter-rouge">session</code>
<strong>variable</strong>. Think of it as a simple web browser inside Python.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">requests_html</span> <span class="kn">import</span> <span class="n">HTMLSession</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">HTMLSession</span><span class="p">()</span>
</code></pre></div></div>

<!-- #md tags=["popout"] -->

<p><strong>HTTP</strong> stands for <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">Hypertext Transfer
Protocol</a>.
It’s the main protocol used for sending around data on the web.</p>

<!-- #endmd -->

<p>We can fetch the page you’re currently reading by calling the <code class="language-plaintext highlighter-rouge">get()</code>
<strong>method</strong> of the <code class="language-plaintext highlighter-rouge">session</code> object and passing it the link to this
website as an <strong>argument</strong>. We get back an HTTP response.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">link</span> <span class="o">=</span> <span class="s">"https://v4py.github.io/intro.html"</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
</code></pre></div></div>

<p>Inspecting the <code class="language-plaintext highlighter-rouge">response</code> variable, we see <code class="language-plaintext highlighter-rouge">&lt;Response [200]&gt;</code>. <code class="language-plaintext highlighter-rouge">200</code> is
the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status">HTTP status
code</a> which
indicates that all went well with our request and we received a
sucessful response.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span>
</code></pre></div></div>

<p>If we don’t know or remember which HTTP status code is which, we can
check that everything is fine by inspecting the <code class="language-plaintext highlighter-rouge">.ok</code> <strong>attribute</strong> on
the <code class="language-plaintext highlighter-rouge">response</code> object.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span><span class="o">.</span><span class="n">ok</span>
</code></pre></div></div>

<p>The contents of the web page are stored in the <code class="language-plaintext highlighter-rouge">.html</code> attribute of the
<code class="language-plaintext highlighter-rouge">response</code> object.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span><span class="o">.</span><span class="n">html</span>
</code></pre></div></div>

<p>That attribute is itself an object with attributes and methods of its
own, which allow us to inspect it and manipulate it. For instance, it
has in turn its own <code class="language-plaintext highlighter-rouge">.html</code> attribute, which contains the raw HTML code
underlying the web page you’re reading, stored as a <strong>string</strong> of
<strong>characters</strong>. We can take a look at a <strong>slice</strong> of the first 50
characters of the string using the <code class="language-plaintext highlighter-rouge">[:50]</code> syntax, just to make sure we
downloaded the right document. If you’re running this notebook inside
JupyterLab, you can delete the square brackets and inspect the full
HTML; I’ve not done that here to save some space.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">html</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span>
</code></pre></div></div>

<p>Uh-oh, I don’t remember reading anything about any doctypes at the
beginning of this text. What’s this all about? Well this is all part of
the HTML language, which tells your browser how to display this web
page. Trouble is, from our point of view as linguists, this is just junk
that we need to get rid of. One thing we could try is the <code class="language-plaintext highlighter-rouge">.text</code>
attribute, which extracts only the text parts of a web page.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the first 50 characters
</span><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">text</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the last 50 characters
</span><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="o">-</span><span class="mi">50</span><span class="p">:]</span>
</code></pre></div></div>

<p>That looks somewhat better, but there’s clearly still some “junk” left.
Turns out that the “text” content of an HTML page includes not only all
the stuff that’s visible on the page (navigation elements, button
labels, and other things we probably want to exclude from our analysis),
but also invisible things like JavaScript programs which add
interactivity to the page (surrounded by <code class="language-plaintext highlighter-rouge">&lt;script/&gt;</code> tags) or CSS styles
which define the layout and other aesthetic aspects of the page
(surrounded by <code class="language-plaintext highlighter-rouge">&lt;style/&gt;</code> tags).</p>

<p>Ideally, we’d like to get rid of all of this. How to achieve that? We
first need to figure out which parts of the HTML enclose the content
we’re interested in. For that, we’ll use our browser’s inspector tools.
If you right click anywhere on this page, you should get a menu where
one of the items says something like <em>Inspect</em> or <em>Inspect Element</em>.
Click on that and a pane will open beside the page which lets you peek
under the hood of this page. If you right click on this paragraph
specifically and select <em>Inspect Element</em>, the inspector will focus on
where in the HTML hierarchy this particular paragraph is placed.</p>

<p><img src="/src/images/intro/inspector.png" alt="Firefox inspector screenshot" /></p>

<p>We can see that this paragraph is contained with a <code class="language-plaintext highlighter-rouge">&lt;div/&gt;</code> HTML element
which has a class of <code class="language-plaintext highlighter-rouge">rendered_html</code>, among others. This sounds like a
property which could be true of all the interesting content on this page
– after all, we know it was <em>rendered</em> from a Jupyter notebook to HTML
– so let’s go on a limb here and retrieve all of those <code class="language-plaintext highlighter-rouge">divs</code> using the
<code class="language-plaintext highlighter-rouge">.find()</code> method. This method uses <a href="https://www.w3schools.com/cssref/css_selectors.asp">CSS
selectors</a> to slice
and dice the page; all we need to know right now is that the syntax to
find all HTML elements of a certain class is to prefix the class name
with a period, so <code class="language-plaintext highlighter-rouge">.rendered_html</code> in our case. We get back a <strong>list</strong>
of <code class="language-plaintext highlighter-rouge">divs</code>; the <code class="language-plaintext highlighter-rouge">clean=True</code> <strong>keyword argument</strong> makes sure that we
throw away those pesky invisible <code class="language-plaintext highlighter-rouge">&lt;script/&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;style/&gt;</code> tags, if
any. Again, I’m showing just a slice of the list to save space – the
first 5 divs using the <code class="language-plaintext highlighter-rouge">[:5]</code> syntax – but you can delete those square
brackets and re-evaluate the cell to see the full list should you wish
so.</p>

<p>```python tags=[“full_width”]
divs = response.html.find(“.rendered_html”, clean=True)
divs[:5]</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;!-- TODO: explain escape sequence or later? --&gt;

Each of these `divs` has a `.text` attribute, which hopefully contains
reasonable text and not some junk. We'd like to lump it all together
into one long string before moving on to further processing, because we
don't really care which part of the text was in which `div`, we just
want to have it all in one place to make things easy. So we can join all
of those `.text` attributes into one string by splicing a **newline**
character, written using the **escape sequence** `"\n"`, in between
every two pieces of text.

```python
string = "\n".join(div.text for div in divs)
string[:30]
</code></pre></div></div>

<!-- TODO: explain function vs. method or later? -->

<p>This is starting to look good! We’ve possibly thrown out some stuff that
could have been included, like the chapter title, but it’s definitely
much better than accidentally including all that JavaScript junk in our
analysis. Just to see how much stuff we’ve gotten rid of, we can compare
the number of characters using the <code class="language-plaintext highlighter-rouge">len()</code> <strong>function</strong>.</p>

<!-- TODO: add something like "we've cut it roughly in half!" based on how -->
<!-- much it turns out to be in the end -->

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">full_text</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">text</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="p">)</span>
</code></pre></div></div>

<p>Now in order to do a frequency analysis, we need to split that text into
words or <strong>tokens</strong>, which is a technical term used when we want to
avoid the kind of philosophical hairsplitting that linguists sometimes
engage in with respect to what is or is not a word. Referring to words
as ‘tokens’ is basically a way of saying, “I don’t want to pick a fight
about the precise meaning of ‘word’ right now, I made a pragmatic
decision to split the text into pieces which broadly make sense, but of
course reasonable people might disagree on the details.” It also allows
us to be precise that we are referring to specific <em>instances</em> of words.
The word ‘word’ is ambiguous, a sentence like “I know I screwed up.” can
be described as containing either 5 (total running) words or 4
(different) words. If we want to avoid confusion, we can say instead
that it consists of <strong>5 tokens</strong> and <strong>4 types</strong>.</p>

<p>Word-splitting or <strong>tokenization</strong> is a trickier problem than it might
seem at first glance, because punctuation keeps getting in the way. So
let’s not do it manually ourselves, let’s use instead the
<code class="language-plaintext highlighter-rouge">word_tokenize()</code> function in the <a href="http://www.nltk.org/"><code class="language-plaintext highlighter-rouge">nltk</code></a>
library, which hopefully covers some of the edge cases we wouldn’t think
of right off the bat if we were to implement it ourselves off the top of
our head. This function <strong>returns</strong> a list of strings, and again we can
do a sanity check by inspecting a slice of it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">tokenized</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="n">tokenized</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">115</span><span class="p">]</span>
</code></pre></div></div>

<p>Looks fine. Notice that before tokenizing the string, we converted in to
<strong>lowercase</strong> using the <code class="language-plaintext highlighter-rouge">.lower()</code> <strong>method</strong>. This is because in our
frequency analysis, we probably don’t want to make a distinction between
e.g. <code class="language-plaintext highlighter-rouge">token</code> and <code class="language-plaintext highlighter-rouge">Token</code>. They refer to the same thing, so they should
be counted together, but the computer doesn’t know that, as far as it’s
concerned, <code class="language-plaintext highlighter-rouge">token</code> is as different from <code class="language-plaintext highlighter-rouge">Token</code> as it is from
<code class="language-plaintext highlighter-rouge">grapefruit</code>, so it’s our job to make them exactly the same by
lowercasing everything beforehand. We can measure the length of the list
and thus get the number of tokens using the <code class="language-plaintext highlighter-rouge">len()</code> function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">tokenized</span><span class="p">)</span>
</code></pre></div></div>

<p>That’s quite a lot, thanks for reading so far!</p>

<p>But hang on, that count is likely to be somewhat inflated. First of all,
a lot of the tokens in the <code class="language-plaintext highlighter-rouge">tokenized</code> list are junk, at least
linguistically speaking, they are special characters related to the
notebook format.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenized</span><span class="p">[:</span><span class="mi">15</span><span class="p">]</span>
</code></pre></div></div>

<p>Second of all, it doesn’t take a linguist to realize that the most
common words in an English text will be words like <code class="language-plaintext highlighter-rouge">a</code> or <code class="language-plaintext highlighter-rouge">the</code>. We
probably don’t want to include those in our frequency analysis, since
they’re not very interesting, they don’t tell us a lot. Luckily, <code class="language-plaintext highlighter-rouge">nltk</code>
has a list of these uninteresting <strong>stopwords</strong> for English which we can
load and store in a <strong>set</strong>, so that we can quickly check if a given
token is a stopword or not. The stopwords are stored in their lowercase
form, so it comes in handy that we already lowercased our input string
prior to tokenizing it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>

<span class="n">stop_list</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">)</span>
<span class="n">stop_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stop_list</span><span class="p">)</span>
<span class="n">stop_list</span><span class="p">[:</span><span class="mi">15</span><span class="p">]</span>
</code></pre></div></div>

<p>We can now get rid of any unwanted tokens. The following code snippet is
a bit more complicated than the previous ones, it involves some
non-linear <strong>control flow</strong>, which is a fancy way of saying the code
doesn’t just linearly execute from top to bottom, but it can run around
in circles for a while (the <strong>for</strong> statement) or potentially skip some
parts depending on whether a condition <strong>evaluates</strong> to true or false
(the <strong>if</strong> statement).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a new empty
</span><span class="n">cleaned</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># iterate over all the tokens in the tokenized list
</span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenized</span><span class="p">:</span>
    <span class="c1"># check if current token is "interesting"
</span>    <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_set</span><span class="p">:</span>
        <span class="c1"># if so, append it to the cleaned list
</span>        <span class="n">cleaned</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
</code></pre></div></div>

<!-- #md tags=["popout"] -->

<p>‡ At least partially – if you actually inspect the contents of <code class="language-plaintext highlighter-rouge">cleaned</code>,
you’ll see that it still contains many tokens, like <code class="language-plaintext highlighter-rouge">cells</code> or
<code class="language-plaintext highlighter-rouge">metadata</code>, which look like regular words, but they don’t occur in this
text, they’re part of the notebook format structure.</p>

<!-- #endmd -->

<p><code class="language-plaintext highlighter-rouge">cleaned</code> is a lot shorter than <code class="language-plaintext highlighter-rouge">tokenized</code>, so it looks like it
worked!‡ Note how Python uses <strong>indentation</strong> to encode the hierarchy
of <strong>statements</strong> in the code: everything which is indented under the
<strong>for-loop header</strong> on the second line is part of the <strong>for-loop body</strong>
and gets executed for each token in the tokenized list. Similarly,
everything indented under the <strong>if header</strong> only gets executed if the
conditional <strong>expression</strong> is satisfied. By dedenting, we escape the
tyranny of those fors and ifs, so that the last line gets executed only
once, after the for-loop has completed.</p>

<p>Notice also that with suitably chosen variable names, Python code can
read almost like English. Readability is one of Python’s main strengths,
though it can sometimes be a pitfall for beginners – when they’re not
sure how to do something in Python, they try to write it in an
English-like way and hope for the best, but this approach can yield
valid Python code which however does something different than the plain
English interpretation would suggest.</p>

<p>We are now finally in a position to create a <strong>frequency distribution</strong>,
using the <code class="language-plaintext highlighter-rouge">nltk.FreqDist</code> <strong>class</strong>. It’s easy, we just pass it our list
of clean tokens.</p>

<!-- #md tags=["popout"] -->

<p>Each object in Python has a <strong>type</strong>. Some of those are built-in, like
strings, lists or sets. But users can also define new types of their
own; those are called <strong>classes</strong>. <code class="language-plaintext highlighter-rouge">nltk.FreqDist</code> is one of those
user-defined types.</p>

<!-- #endmd -->

<p>```python tags=[“output_scroll”]
freq_dist = nltk.FreqDist(cleaned)
freq_dist</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
We can access individual **values** inside the frequency distribution by
requesting them using the corresponding **key**.

```python
freq_dist["python"]
</code></pre></div></div>

<p>We can also list the top $n$ items using the <code class="language-plaintext highlighter-rouge">.most_common()</code> method.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">freq_dist</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p>Based on the most frequent lexical items, it looks like this is a text
about Python programming and language data! That checks out.</p>

<p>Finally, we can visualize this result using a wordcloud, to get a quick
and intuitive overview of these important words.</p>

<p>```python tags=[“full_width”]
from corpy.vis import wordcloud</p>

<p>wordcloud(freq_dist, size=(800, 400), rounded=True)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Whew! That was actually a lot of work. Now that we've figured out how to
do this, we could package all of these steps into a reusable recipe, so
that we don't have to re-cobble all of this together if we want to run a
same analysis on a different chapter. We can do so by writing a
function. Again, as with for-loops and if statements, everything that's
indented under the function header starting with `def` is part of the
function body, and will be run step by step each time the function is
**called**.

```python
def chapter_wordcloud(link, size=(800, 400), rounded=True):
    session = HTMLSession()
    response = session.get(link)
    divs = response.html.find(".rendered_html", clean=True)
    string = "\n".join(div.text for div in divs)
    tokenized = nltk.word_tokenize(string.lower())
    stop_set = set(nltk.corpus.stopwords.words("english"))
    cleaned = []
    for token in tokenized:
        if token.isalpha() and token not in stop_set:
            cleaned.append(token)
    # if we want just the wordcloud, we can also directly create it from
    # a list of tokens, without making an intermediate nltk.FreqDist
    return wordcloud(cleaned, size=size, rounded=rounded)
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">return</code> keyword specifies what the result is that the function
spits out at the other end. Once the function reaches a return
statement, it stops execution and gives the result back to whoever
called the function.</p>

<p>We can now easily create a wordcloud based on the final chapter of this
book, for comparison.</p>

<p>```python tags=[“full_width”]
chapter_wordcloud(“https://v4py.github.io/outro.html”)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Indeed, we can use this function on any chapter in any online book
created (much like the present book) with the [jupyter-book]() package,
because they all use the same HTML structure. For instance, here's a
wordcloud of the chapter on [*Regular
Expressions*](https://www.textbook.ds100.org/ch/08/text_regex.html) from
the book [*Principles and Techniques of Data
Science*](https://www.textbook.ds100.org/).

```python tags=["full_width"]
chapter_wordcloud("https://www.textbook.ds100.org/ch/08/text_regex.html")
</code></pre></div></div>

<p>This is the real power of programming: once you’ve figured out and
tweaked a processing and analysis recipe, you can apply it to similar
data with lightning speed and each time consistently in exactly the same
way.</p>

<p>To wrap up, let me reiterate that I realize this is a lot to take in if
this is your first time seeing Python code, and even more so if this is
your first time seeing any programming language code whatsoever. Again,
it’s totally fine if you don’t understand all the details at this point.
I encourage you to revisit this extended worked example once you’re done
reading the book, as a way to reflect on what you’ve learned and bring
it all together.</p>

<!-- TODO: remove or develop -->

<!-- # NLTK Book -->

<!-- A great, longer free resource. <http://www.nltk.org/book/> -->

<!-- ![NLTK Book](./nltk_book.jpg) -->

<!-- Credit: ??? -->

<!-- # The NLP pipeline -->

<!-- NOTE: maybe leave this out? Not strictly necessary, this is probably -->
<!-- better to discuss in class, plus I shouldn't rely too much on NLTK Book -->
<!-- materials for licensing reasons. -->

<!-- ![NLP](./dialogue.png) -->

<!-- Credit: ??? -->

<!-- # Overview -->

<!-- - Python basics (functions, control flow, collections) -->
<!-- - The NLTK [package](http://www.nltk.org/) & -->
<!--   [book](http://www.nltk.org/book) as a good starting point for people -->
<!--   interested in language data -->
<!-- - [How text is represented inside -->
<!--   computers](https://dlukes.github.io/unicode.html) -->
<!-- - Regular expressions in Python -->
<!-- - Accessing web services ("REST APIs") from Python & Automatic -->
<!--   annotation of language data (tagging, parsing) - both courtesy of -->
<!--   [Rudolf Rosa](https://ufal.mff.cuni.cz/rudolf-rosa) -->
<!-- - Getting data into Python (raw text & tabular data) -->
<!-- - Some visualizations (dispersion plots, wordclouds) -->
<!-- - Case studies: collocation strength, keyword analysis -->

<!-- vim: set spell spelllang=en: -->

            </div>
            <div class="c-textbook__footer" id="textbook_footer">
              
<nav class="c-page__nav">
  

  
</nav>

              <footer>
  <p class="footer">Sponsored by <a href="https://www.visegradfund.org/">Visegrad Fund</a> grant nr. 21820079 "Training Digital Scholars: Knowledge Exchange between V4 and Austria". Available under the terms of the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> license.</p>
</footer>

            </div>

        </div>
      </main>
    </div>
  </body>
</html>
